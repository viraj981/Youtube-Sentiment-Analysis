{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LDezQB0dHAX7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "import re \n",
    "import nltk \n",
    "\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, make_scorer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from time import time\n",
    "\n",
    "# from sklearn import svm\n",
    "import xgboost as xgb\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8jshMn_tIoud",
    "outputId": "979605b4-e16e-40a4-9b66-e4abbfb250e1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "  \n",
    "df = pd.read_csv(r'C:\\Users\\Acer\\Desktop\\NLP project/train.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImjU92r2OgX-"
   },
   "source": [
    "Preview of CLASS in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "Ew5DqLBhGqYA",
    "outputId": "e1ba5dd0-5112-4ed7-86e7-4583cc9b941a"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "tot = df.shape[0]\n",
    "num_toxic = df[df.CLASS == 0].shape[0]\n",
    "\n",
    "slices = [num_toxic/tot,(tot - num_toxic)/tot]\n",
    "labeling = ['Non-Advertise Content','Advertise Content']\n",
    "explode = [0.2,0]\n",
    "plt.figure(figsize=(4,8))\n",
    "plt.pie(slices,explode=explode,shadow=True,autopct='%1.1f%%',labels=labeling,wedgeprops={'edgecolor':'black'})\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kQeopRXbJwnk"
   },
   "outputs": [],
   "source": [
    "df['length_train'] = df['CONTENT'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hxu-MnhlKEXn"
   },
   "outputs": [],
   "source": [
    "combi = df.append(df,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6JrTAt3TKGnN"
   },
   "outputs": [],
   "source": [
    "def remove_pattern(input_txt,pattern):\n",
    "  r= re.findall(pattern,input_txt)\n",
    "  for i in r:\n",
    "    input_txt = re.sub(i,'',input_txt)\n",
    "  return input_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lemKe-DnKImw"
   },
   "outputs": [],
   "source": [
    "#removes @user\n",
    "combi['tidy_content'] = np.vectorize(remove_pattern)(combi['CONTENT'],\"@[\\w]*\")\n",
    "#removes extra letters \n",
    "combi['tidy_content'] = combi['tidy_content'].str.replace(\"[^a-zA-z#]\",\" \")\n",
    "#removes all those words with size less than 3 \n",
    "combi['tidy_content']= combi['tidy_content'].apply(lambda x : ' '.join([w for w in x.split() if len(w)>3])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "id": "q92-RknGKP6y",
    "outputId": "ed309c08-6723-42a7-81a8-caf35970facf"
   },
   "outputs": [],
   "source": [
    "combi.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3-ulnftyKTT4"
   },
   "outputs": [],
   "source": [
    "tokenized_tweet = combi['tidy_content'].apply(lambda x: x.split()) #creates a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XvrWi0r4Kgrm",
    "outputId": "f7e19ae4-55a7-4678-f5d8-772e91bd1c80"
   },
   "outputs": [],
   "source": [
    "tokenized_tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bwFUqhjyKjx9",
    "outputId": "677075f1-dce1-419c-8fdc-83ae05249ab0"
   },
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "tokenized_tweet = tokenized_tweet.apply(lambda x: [lemmatizer.lemmatize(i) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yC8DHJItKmME"
   },
   "outputs": [],
   "source": [
    "for i in range(len(tokenized_tweet)):\n",
    "  tokenized_tweet[i] = ' '.join(tokenized_tweet[i])\n",
    "combi['tidy_tweet'] = tokenized_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "vnrJzgkxKpF5",
    "outputId": "aef4b3d1-6a51-4608-bf8c-da04691b299e"
   },
   "outputs": [],
   "source": [
    "combi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ul7cAxycKthI",
    "outputId": "b8ae37b4-92fd-4d15-d219-5b3a27547a38"
   },
   "outputs": [],
   "source": [
    "# splitting data \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['CONTENT'], \n",
    "                                                    df['CLASS'], \n",
    "                                                    random_state=42)  \n",
    "           \n",
    "print('Number of rows in the total set: {}'.format(df.shape))\n",
    "print('Number of rows in the training set: {}'.format(X_train.shape))\n",
    "print('Number of rows in the test set: {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "usjH05k5Lj-7",
    "outputId": "f2f7b313-55b0-47e9-ad4a-22e0d1891a1b"
   },
   "outputs": [],
   "source": [
    "# Instantiate the CountVectorizer method\n",
    "count_vector = CountVectorizer(stop_words = 'english', lowercase = True)\n",
    "\n",
    "# Fit the training data and then return the matrix\n",
    "training_data = count_vector.fit_transform(X_train)\n",
    "print(X_train.shape)\n",
    "print(training_data.shape)\n",
    "\n",
    "# Transform testing data and return the matrix. Note we are not fitting the testing data into the CountVectorizer()\n",
    "testing_data = count_vector.transform(X_test)\n",
    "\n",
    "# making pickle file\n",
    "import pickle\n",
    "filename = 'vector_vocabulary.pkl'\n",
    "pickle.dump(count_vector.vocabulary_, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iz4pF3_MLpp0"
   },
   "outputs": [],
   "source": [
    "def pipeline(learner_list, X_train, y_train, X_test, y_test): \n",
    "    '''\n",
    "    inputs:\n",
    "       - learner: the learning algorithm to be trained and predicted on\n",
    "       - X_train: features training set\n",
    "       - y_train: income training set\n",
    "       - X_test: features testing set\n",
    "       - y_test: income testing set\n",
    "    '''\n",
    "    \n",
    "    # Get length of Training Data:\n",
    "    size = len(y_train)\n",
    "    \n",
    "    results = {}\n",
    "    final_results = []\n",
    "    \n",
    "    import pickle\n",
    "    for learner in learner_list:\n",
    "        \n",
    "        print(learner)\n",
    "        # Store the learner name:\n",
    "        results['Algorithm'] = learner.__class__.__name__\n",
    "\n",
    "        # Fit the learner:\n",
    "        start = time() # Get start time\n",
    "        print(\"Training {}\".format(learner.__class__.__name__))\n",
    "        learner = learner.fit(X_train, y_train)\n",
    "        end = time() # Get end time\n",
    "\n",
    "        # making pickle file here for my various classifier\n",
    "\n",
    "        filename = learner.__class__.__name__+\".pkl\"\n",
    "        pickle.dump(learner, open(filename, 'wb'))\n",
    "\n",
    "\n",
    "        # Store the training time\n",
    "        results['Training Time'] = end - start\n",
    "\n",
    "        start = time() # Get start time\n",
    "        predictions_test = learner.predict(X_test)\n",
    "        predictions_train = learner.predict(X_train)\n",
    "        end = time() # Get end time\n",
    "\n",
    "        # Store the prediction time\n",
    "        results['Prediction Time'] = end - start\n",
    "\n",
    "        # Compute the Accuracy on Test Set\n",
    "        results['Accuracy: Test'] = accuracy_score(y_test, predictions_test)\n",
    "\n",
    "        # Compute the Accuracy on Training Set\n",
    "        results['Accuracy: Train'] = accuracy_score(y_train, predictions_train)\n",
    "\n",
    "        # Compute the F1 Score on Test Set\n",
    "        results['F1 Score: Test'] = f1_score(y_test, predictions_test)\n",
    "\n",
    "        # Compute the F1 Score on Training Set\n",
    "        results['F1 Score: Train'] = f1_score(y_train, predictions_train)\n",
    "\n",
    "        # Compute the Precision on Test Set\n",
    "        results['Precision: Test'] = precision_score(y_test, predictions_test)\n",
    "\n",
    "        # Compute the Precision on Training Set\n",
    "        results['Precision: Train'] = precision_score(y_train, predictions_train)\n",
    "\n",
    "        # Compute the Recall on Test Set\n",
    "        results['Recall: Test'] = recall_score(y_test, predictions_test)\n",
    "\n",
    "        # Compute the Recall on Training Set\n",
    "        results['Recall: Train'] = recall_score(y_train, predictions_train)\n",
    "\n",
    "        # Success\n",
    "        print(\"Training {} finished in {:.2f} sec\".format(learner.__class__.__name__, results['Training Time']))\n",
    "        print('----------------------------------------------------')\n",
    "        \n",
    "        final_results.append(results.copy())\n",
    "    # Return a dataframe of the results\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v39ZPTKNLpxo"
   },
   "outputs": [],
   "source": [
    "# make a list of models\n",
    "models = [LinearSVC(), \n",
    "          RandomForestClassifier(),\n",
    "         LogisticRegression(), KNeighborsClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ruM_PZ5SMIRD",
    "outputId": "b21dc14b-3af9-4de0-f567-8a2f23290ec3"
   },
   "outputs": [],
   "source": [
    "re = pipeline(models, training_data, y_train, testing_data, y_test)\n",
    "results = pd.DataFrame(re)\n",
    "results = results.reindex(columns = ['Algorithm', 'Accuracy: Test', 'Precision: Test', 'Recall: Test', 'F1 Score: Test', 'Prediction Time',\n",
    "                          'Accuracy: Train', 'Precision: Train', 'Recall: Train', 'F1 Score: Train', 'Training Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "De-VNpFLML9W"
   },
   "outputs": [],
   "source": [
    "results = results.reindex(columns = ['Algorithm', 'Accuracy: Test', 'Precision: Test', 'Recall: Test', 'F1 Score: Test', 'Prediction Time',\n",
    "                          'Accuracy: Train', 'Precision: Train', 'Recall: Train', 'F1 Score: Train', 'Training Time'])\n",
    "\n",
    "results.sort_values(by = 'F1 Score: Test', inplace = True, ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 192
    },
    "id": "5Plgx86BMPfJ",
    "outputId": "8a35716e-e323-4d48-f54e-dbd663ba5d67"
   },
   "outputs": [],
   "source": [
    "results.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "id": "11G1GKBHMuiV",
    "outputId": "48db1482-6a5d-4f59-8362-baa1c5f0afc3"
   },
   "outputs": [],
   "source": [
    "results.describe().loc[['min', 'max'], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kZIr3bf4JM_n"
   },
   "outputs": [],
   "source": [
    "best_acc = results[results['Accuracy: Test'] == results['Accuracy: Test'].max()]\n",
    "best_f1 = results[results['F1 Score: Test'] == results['F1 Score: Test'].max()]\n",
    "best_precision = results[results['Precision: Test'] == results['Precision: Test'].max()]\n",
    "best_recall = results[results['Recall: Test'] == results['Recall: Test'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "id": "3rke-NVlJfJw",
    "outputId": "c154ff5e-5a62-4ed0-cf26-f9af032ab619"
   },
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "plt.figure(figsize = (10, 5))\n",
    "\n",
    "barWidth = 0.2\n",
    " \n",
    "# set height of bar\n",
    "bars1 = results['Accuracy: Test']\n",
    "bars2 = results['F1 Score: Test']\n",
    "bars3 = results['Precision: Test']\n",
    "bars4 = results['Recall: Test']\n",
    "\n",
    " \n",
    "# Set position of bar on X axis\n",
    "r1 = np.arange(len(bars1))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "r3 = [x + barWidth for x in r2]\n",
    "r4 = [x + barWidth for x in r3]\n",
    "\n",
    " \n",
    "# Make the plot\n",
    "pal = sns.color_palette()\n",
    "plt.bar(r1, bars1, color= pal[0], width=barWidth, edgecolor='white', label='Test Accuracy')\n",
    "plt.bar(r2, bars2, color= pal[1], width=barWidth, edgecolor='white', label='F1 Score')\n",
    "plt.bar(r3, bars3, color= pal[2], width=barWidth, edgecolor='white', label='Precision')\n",
    "plt.bar(r4, bars4, color= pal[4], width=barWidth, edgecolor='white', label='Recall')\n",
    "\n",
    " \n",
    "# Add xticks on the middle of the group bars\n",
    "plt.xlabel('Algorithm', fontweight='bold', fontsize = 15)\n",
    "plt.ylabel('Score', fontweight = 'bold', fontsize = 15)\n",
    "plt.xticks([r + barWidth for r in range(len(bars1))], results['Algorithm'], rotation = 15, fontsize = 12)\n",
    " \n",
    "# Create legend & Show graphic\n",
    "plt.legend(fontsize = 12)\n",
    "\n",
    "textstr = '\\n'.join(['Best Accuracy: {:.3f} - {}'.format(best_acc['Accuracy: Test'].values[0], best_acc['Algorithm'].values[0]), \n",
    "                     'Best F1 Score: {:.3f} - {}'.format(best_f1['F1 Score: Test'].values[0], best_f1['Algorithm'].values[0]),\n",
    "                   'Best Precision: {:.3f} - {}'.format(best_precision['Precision: Test'].values[0], best_precision['Algorithm'].values[0]), \n",
    "                    'Best Recall: {:.3f} - {}'.format(best_recall['Recall: Test'].values[0], best_recall['Algorithm'].values[0])])\n",
    "props = dict(boxstyle='round', facecolor='lightgrey', alpha=0.5)\n",
    "\n",
    "#place a text box\n",
    "plt.text(9.2, 1, textstr, fontsize=12,\n",
    "        verticalalignment='top', bbox=props)\n",
    "\n",
    "plt.title('Classification Summary of Algorithms', fontweight = 'bold', fontsize = 17);\n",
    "print(\"click to zoom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BK4FnwXvMx9Q",
    "outputId": "4e40817a-119b-476d-d91a-c404bda19110"
   },
   "outputs": [],
   "source": [
    "# I am testing my classifier and pre-processing stages\n",
    "\n",
    "data = [\"hello\"]\n",
    "count_vector = CountVectorizer(stop_words = 'english', lowercase = True,vocabulary=pickle.load(open(\"vector_vocabulary.pkl\", \"rb\")))\n",
    "data=count_vector.transform(data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C8Q5AytNNcxO",
    "outputId": "dca74404-1647-492e-94c5-66ae4a2b9cf8"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "trained_model=pickle.load(open(\"LinearSVC.pkl\", 'rb'))\n",
    "\n",
    "# print(testing_data)\n",
    "print(trained_model.coef_.shape)\n",
    "\n",
    "# print(X_test[0])\n",
    "# print(testing_data[0][0])\n",
    "\n",
    "print(trained_model.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HXmSGPAuKv6B"
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "PctIikOAZDUk",
    "outputId": "d66b7c92-8889-445b-eb08-69bbe36d9eb7"
   },
   "outputs": [],
   "source": [
    "test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z19rwsesZEMx"
   },
   "outputs": [],
   "source": [
    "test1 = test[['ID', 'CONTENT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "6x4_7kMcZnTk",
    "outputId": "301a7c3e-f674-49b0-d195-8f47ee749a6b"
   },
   "outputs": [],
   "source": [
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6bpVuFUeZq1A"
   },
   "outputs": [],
   "source": [
    "op= []\n",
    "#value = combi['CONTENT'].apply(lambda x:x.split())\n",
    "for i in test1['CONTENT']:\n",
    "  \n",
    "  data = [i]\n",
    "  count_vector = CountVectorizer(stop_words = 'english', lowercase = True,vocabulary=pickle.load(open(\"vector_vocabulary.pkl\", \"rb\")))\n",
    "  data=count_vector.transform(data)\n",
    "  trained_model=pickle.load(open(\"LinearSVC.pkl\", 'rb'))\n",
    "  #print(trained_model.predict(data))\n",
    "  op.append(trained_model.predict(data).flatten().tolist()[0])\n",
    "  #value['output'] = trained_model.predict(data)\n",
    "\n",
    "\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jZEF2x5_mx1A",
    "outputId": "13bdec23-638d-4704-d6ea-a1bec5444c01"
   },
   "outputs": [],
   "source": [
    "test1['CLASS'] = op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "44Fdg0KBnN10",
    "outputId": "851dab93-aec6-42fd-faac-90b9e57fada4"
   },
   "outputs": [],
   "source": [
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DFZlsJtKnO9Q",
    "outputId": "40d76f57-e52f-46bd-f4d6-42d10e525111"
   },
   "outputs": [],
   "source": [
    "test1.drop('CONTENT', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fVvzl3XInczc"
   },
   "outputs": [],
   "source": [
    "test1.set_index('ID', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MECHS5S5nvSK"
   },
   "outputs": [],
   "source": [
    "print(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MeNspdLDoZ29"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "ZS_SourceCode.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
